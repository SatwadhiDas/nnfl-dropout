{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dropout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SatwadhiDas/nnfl-dropout/blob/master/dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E49TZc1HfzTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import decimal\n",
        "import os\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlDu3ahLjFfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOl9AGeOjG6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def findValueN(prob):\n",
        "    # pn = 256 for 2 first hidden layers\n",
        "    # pn = 512 for last layer\n",
        "        # n values are the number of hidden units at each layer\n",
        "    n1 = int(256.0/prob)\n",
        "    n2 = int(256.0/prob)\n",
        "    n3 = int(512.0/prob)\n",
        "    n = [n1,n2,n3,prob]\n",
        "        # return number o\n",
        "    float(n[3])\n",
        "    return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXoA46p7jMfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addPValue(prob):\n",
        "        # layers all have 2048 hidden units as described in the research paper\n",
        "    n1 = 2048\n",
        "    n2 = 2048\n",
        "    n3 = 2048\n",
        "    n = [n1,n2,n3,prob]\n",
        "    float(n[3])\n",
        "    return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWO61_hajXpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def runDropout(*layer):\n",
        "        # Sequential model and the layers that describe the model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape, activation=\"relu\"))\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "    model.add(Dense(layer[0], activation='relu'))\n",
        "    model.add(Dropout(layer[3]))\n",
        "    model.add(Dense(layer[1], activation='relu'))\n",
        "    model.add(Dropout(layer[3]))\n",
        "    model.add(Dense(layer[2], activation='relu'))\n",
        "    model.add(Dropout(layer[3]))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "        # Configure model before training\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "    batch_size = 128\n",
        "    epochs = 10\n",
        "\n",
        "        # Train the model for a fixed number of epochs\n",
        "    history_dropout = model.fit_generator(training_set, \n",
        "                         steps_per_epoch=60000//64, \n",
        "                         validation_data= test_set, \n",
        "                         validation_steps=10000//64, \n",
        "                         epochs=10)\n",
        "    \n",
        "    y_pred=model.predict_classes(x_test);\n",
        "    y_test_res = y_test.reshape(1,y_test.shape[0],1);\n",
        "    y_pred_res = y_pred.reshape(1,y_test.shape[0],1);\n",
        "    print(tf.image.psnr(y_test_res,y_pred_res,max_val=1.0),'PSNR VALUE')\n",
        "\n",
        "        # Training accuracy\n",
        "    accuracy = history_dropout.history['accuracy']\n",
        "    train_err = 100.0 - 100.0*(accuracy[-1])\n",
        "\n",
        "        # Test Accuracy\n",
        "            # Validation accuracy possibly not same as Test accuracy\n",
        "    val_acc = history_dropout.history['val_accuracy']\n",
        "    test_err = 100.0 - 100.0*(val_acc[-1])\n",
        "    # *** Calculate error bars HERE ***\n",
        "    finalError = [test_err, train_err, layer[3]]\n",
        "    return finalError\n",
        "    # END OF RUN DROPOUT #\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwoF5QCRjg25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def floatRange(start, stop, step):\n",
        "  while start <= stop:\n",
        "    yield float(start)\n",
        "    start += decimal.Decimal(step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvcnWM5Qjpcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def runForAllP():\n",
        "    # lists to store ploting values locally\n",
        "        # figure a error\n",
        "    a_test_error = []\n",
        "    a_train_error = []\n",
        "        # figure b error\n",
        "    b_test_error = []\n",
        "    b_train_error = []\n",
        "        # returns the list of p values from 0.1-1.0, into list\n",
        "    pValues = [0.1,0.2]\n",
        "    pValues1 = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "\n",
        "    print(pValues)\n",
        "    # run dropout on all values of p for both figures\n",
        "    for i in pValues:\n",
        "        varyLayer = findValueN(i)\n",
        "        constLayer = addPValue(i)\n",
        "            # Store error values for figure a\n",
        "        errorFigA = runDropout(*constLayer)\n",
        "        a_test_error.append(errorFigA[0])\n",
        "        a_train_error.append(errorFigA[1])\n",
        "        print(\"a_train_error\")\n",
        "        print(a_train_error)\n",
        "        print(\"\\n\")\n",
        "        print(\"a_test_error\")\n",
        "        print(a_test_error)\n",
        "        print(\"\\n\")\n",
        "    for i in pValues:\n",
        "        varyLayer = findValueN(i)\n",
        "        constLayer = addPValue(i)\n",
        "        errorFigB = runDropout(*varyLayer)\n",
        "        # Store error values for figure b\n",
        "        b_test_error.append(errorFigB[0])\n",
        "        b_train_error.append(errorFigB[1])\n",
        "        print(\"b_train_error\")\n",
        "        print(b_train_error)\n",
        "        print(\"\\n\")\n",
        "        print(\"b_test_error\")\n",
        "        print(b_test_error)\n",
        "        print(\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqQn4QfNj6IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) =mnist.load_data()\n",
        "\n",
        "# Reshaping the array to 4-dims so that it can work with the API\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "# Set values to float so that we can get decimal points after division\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "train_gen = ImageDataGenerator(rotation_range=8, \n",
        "                               width_shift_range=0.08, \n",
        "                               shear_range=0.3, \n",
        "                               height_shift_range=0.08, \n",
        "                               zoom_range=0.08 )\n",
        "test_gen = ImageDataGenerator()\n",
        "\n",
        "training_set= train_gen.flow(x_train, y_train, batch_size=64)\n",
        "test_set= train_gen.flow(x_test, y_test, batch_size=64)\n",
        "\n",
        "\n",
        "    # close to the results in the figure\n",
        "runForAllP()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}